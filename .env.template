# AI Command Gateway Configuration Template
# Copy this file to .env and fill in your values

# ---- Gateway Identification ----
GATEWAY_INSTANCE_ID=local-dev-gateway-01
LOG_LEVEL=INFO

# ---- Internal LLM Configuration ----
LLM_PROVIDER=openai
LLM_MODEL_NAME=gpt-3.5-turbo
LLM_API_KEY=your-openai-api-key-here
LLM_API_BASE_URL=https://api.openai.com/v1/
LLM_SYSTEM_PROMPT=You are an expert assistant that translates user intents for managing services into precise Docker CLI commands. The user will provide an intent and a target Docker container name. Respond ONLY with the Docker CLI command string. Do not add any explanation or conversational fluff.

# ---- Execution Strategy ----
# Valid values: "local_socket", "ssh"
EXECUTION_STRATEGY=local_socket

# ---- Container Name Mappings (Local Environment) ----
# The devops-ai-agent will send logical_name, e.g., "market-predictor"
# The gateway needs to know the actual container name in this environment
CONTAINER_NAME_FOR_MARKET_PREDICTOR=infrastructure-market-predictor
CONTAINER_NAME_FOR_CODING_AI_AGENT=infrastructure-coding-ai-agent
CONTAINER_NAME_FOR_DEVOPS_AI_AGENT=infrastructure-devops-ai-agent

# ---- SSH Configuration (only needed if EXECUTION_STRATEGY=ssh) ----
# SSH_TARGET_HOST=192.168.1.100
# SSH_TARGET_USER=opc
# SSH_PRIVATE_KEY_PATH=/app/secrets/ssh_key

# ---- API Configuration ----
API_HOST=0.0.0.0
API_PORT=8080
CORS_ORIGINS=http://localhost:8001

# ---- Timeouts and Limits ----
COMMAND_TIMEOUT_SECONDS=30
MAX_COMMAND_OUTPUT_LENGTH=10000